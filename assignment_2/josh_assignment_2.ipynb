{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alwOsIlVboj3"
   },
   "source": [
    "# Graded Exercise 2: Anomaly Detection on Acoustic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uvNdd91bvDF"
   },
   "source": [
    "- **Course**: [CIVIL-426 - Machine Learning for Predictive Maintenance](https://edu.epfl.ch/coursebook/en/machine-learning-for-predictive-maintenance-applications-CIVIL-426)\n",
    "- **Start Date**: 2024.10.03 at 10:15\n",
    "- **Due Date**: 2024.10.23 at 23:59\n",
    "- **Student 0**:\n",
    "    - Name: `FILL HERE`\n",
    "    - SCIPER: `FILL HERE`\n",
    "- **Student 1**:\n",
    "    - Name: `FILL HERE`\n",
    "    - SCIPER: `FILL HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Anomalous sound detection (ASD) refers to the task of identifying whether the sounds emitted from a target machine are normal or anomalous.\n",
    "In real-world industrial environments, anomalies are infrequent and can exhibit significant variability, making it impractical to build an exhaustive set of anomalous sound patterns.\n",
    "As a result, our goal is to detect anomalous sounds using only normal sound clips for training.\n",
    "\n",
    "This challenge cannot be approached as a simple classification problem (anomaly vs healthy). Instead, it is formulated as a **one-class classification** problem, where the model is trained on normal sound data to detect deviations from the learned pattern.\n",
    "\n",
    "Anomalous sound detection can be achieved with following steps:\n",
    "   - Feature Extraction (I)\n",
    "   - One-class Classifier Training (II)\n",
    "   - Decisions based on a threshold from your trained classifier (III)\n",
    "   \n",
    "Through this assignment, you will primarily focus on tasks (I) and (II).\n",
    "The quality of your one-class classifier will be assessed using the **Area Under the Curve (AUC)** score on the test dataset.\n",
    "\n",
    "The model used here is a type of neural network called **AutoEncoder** (AE). AE is trained to reconstruct the input data while compressing the input data into a lower-dimensional latent space and minimizing information loss during this process.\n",
    "Thus, you will also modify the extracted features and Neural Network used in this notebook to improve the anomalous sound detection performance.\n",
    "\n",
    "The dataset is composed of two different machines, a Pump and a Valve. For each machine you have:\n",
    "- A **training dataset** composed of *only healthy* sound data\n",
    "- A **test dataset** composed of *both healthy and abnormal* sound data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions:\n",
    "\n",
    "Your task is to improve the anomalous sound detection performance by modifying the feature extraction process and neural network architecture. You are expected to experiment with various feature representations and neural network configurations to optimize detection results.\n",
    "\n",
    "Specifically, the following questions must be addressed. Each question should be discussed separately for both the Pump and Valve datasets. The answers are to be provided in a PDF report, and the full Jupyter notebook must also be submitted.\n",
    "\n",
    "**Question 1:** Given the provided code, fill in the blank spaces to extract signal features, train a simple AutoEncoder that reconstructs the inputs MEL-Spectogram, and report the AUC score.\n",
    "\n",
    "**Question 2:** From the trained AutoEncoder, use the bottleneck features to train both (1) a One-Class SVM and (2) an Isolation Forest, and report the corresponding AUC scores.\n",
    "\n",
    "**Question 3:** Instead of using AutoEncoder features, apply PCA to project the MEL-spectrogram into a smaller dimensional space, then train (1) a One-Class SVM and (2) an Isolation Forest, and report the AUC scores.\n",
    "\n",
    "**Question 4:** Determine an appropriate threshold for distinguishing anomalies based on the given results, and compute the following metrics: Accuracy, True Positive Rate (TPR), False Positive Rate (FPR), and F1-score.\n",
    "\n",
    "**Question 5:** Visualize essential steps and provide a thorough discussion of the results obtained from all the methods.  \n",
    "\n",
    "**Bonus Question:** Modify the AutoEncoder architecture to a 2D AutoEncoder using convolutional layers instead of fully connected layers, and analyze its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AalklIEQg09y"
   },
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gdown --upgrade --quiet\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pump Dataset\n",
    "gdown.download(id='1ZAqnNW2gnHDyFHGHk3Aru7k-ng-BTpGn', output=\"./dev_data_pump_04.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valve Dataset\n",
    "gdown.download(id='1H_SS7qteLcd44e5CD9CFJjhJ573FAb6M', output=\"./dev_data_valve_00.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case that above links do not work, you can also manully download the dataset here:\n",
    "- **dev_data_pump_04.zip**: https://docs.google.com/uc?export=download&id=1ZAqnNW2gnHDyFHGHk3Aru7k-ng-BTpGn\n",
    "- **dev_data_valve_00,zip**: https://docs.google.com/uc?export=download&id=1H_SS7qteLcd44e5CD9CFJjhJ573FAb6M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MgKKujQsg3R6",
    "outputId": "20831466-937b-4715-b210-f298dbecf5b1"
   },
   "outputs": [],
   "source": [
    "!unzip dev_data_pump_04.zip\n",
    "!unzip dev_data_valve_00.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_BOUpwEg6hT"
   },
   "source": [
    "## Import Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vnb2HZBvg8FQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import librosa\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rj7toOo8g93H"
   },
   "source": [
    "## Audio Data Loading and MEL-Spectrogram Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uO8WNShag_tM"
   },
   "source": [
    "The code is adapted from https://github.com/MIMII-hitachi/mimii_baseline\n",
    "\n",
    "Copyright (C) 2019 Hitachi, Ltd. All right reserved.\n",
    "\n",
    "Harsh Purohit, Ryo Tanabe, Kenji Ichige, Takashi Endo, Yuki Nikaido, Kaori Suefusa, and Yohei Kawaguchi, \"MIMII Dataset: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection,\" arXiv preprint arXiv:1909.09347, 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fy51-G6qg4RJ"
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# import additional python-library\n",
    "########################################################################\n",
    "import librosa.core\n",
    "import librosa.feature\n",
    "\n",
    "# WAV File Input\n",
    "def load_wav_files(wav_file_name, mono=True):\n",
    "    \"\"\"Load a .wav file.\"\"\"\n",
    "    try:\n",
    "        return librosa.load(wav_file_name, sr=None, mono=mono)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load file '{wav_file_name}'. Error: {e}\")\n",
    "        raise\n",
    "\n",
    "def demux_wav_files(wav_file_name, channel=0):\n",
    "    \"\"\"Demux a .wav file and return a specific channel.\"\"\"\n",
    "    try:\n",
    "        multi_channel_data, sr = load_wav_files(wav_file_name, mono=False)\n",
    "        if multi_channel_data.ndim == 1:\n",
    "            return sr, multi_channel_data\n",
    "        return sr, multi_channel_data[channel, :]\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in demuxing file '{wav_file_name}': {e}\")\n",
    "        raise\n",
    "\n",
    "# Feel free to modify and analysis the images in your report\n",
    "def plot_signals(tmin, tmax, sr, y, emphasized_y, log_mel_spectrogram):\n",
    "    plt.figure(1)\n",
    "    n = len(y)\n",
    "    t = np.linspace(tmin, tmax, n)\n",
    "    plt.plot(t, y)\n",
    "    plt.xlim(t[0],t[-1])\n",
    "    plt.xlabel('time/s',fontsize=20)\n",
    "    plt.ylabel('Amplitude',fontsize=20)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.figure(2)\n",
    "    freq = sr/n*np.linspace(0,n/2,int(n/2)+1)\n",
    "    plt.plot(freq,np.absolute(np.fft.rfft(y[tmin*sr:tmax*sr],n)**2)/n)\n",
    "    plt.xlim(0,5000)\n",
    "    plt.xlabel('Frequency/Hz',fontsize=14)\n",
    "    \n",
    "    plt.figure(3)\n",
    "    plt.plot(freq,np.absolute(np.fft.rfft(emphasized_y,n)**2)/n)\n",
    "    plt.xlim(0,5000)\n",
    "    plt.xlabel('Frequency/Hz',fontsize=14)\n",
    "    \n",
    "    plt.figure(4)\n",
    "    librosa.display.specshow(log_mel_spectrogram)\n",
    "    plt.colorbar()\n",
    "\n",
    "########################################################################\n",
    "# Feature Extractor\n",
    "########################################################################\n",
    "def file_to_features(file_name,\n",
    "                     n_mels=64,\n",
    "                     frames=5,\n",
    "                     n_fft=1024,\n",
    "                     hop_length=512,\n",
    "                     power=2.0,\n",
    "                     plot=True):\n",
    "    \"\"\"Convert a WAV file to a vector array.\"\"\"\n",
    "    # Step 01: Load the demuxed wav files\n",
    "    sr, y = demux_wav_files(file_name, channel=0)\n",
    "    \n",
    "    # Step 02: Signal Pre-emphasis\n",
    "    tmin = int(0)\n",
    "    tmax = int(len(y)/sr)\n",
    "    alpha = 0.95\n",
    "    emphasized_y = np.append(y[0],\n",
    "                             y[1:] - alpha*y[:-1])\n",
    "    \n",
    "    # Step 03: Generate MEL-Spectrogram\n",
    "    # ===================================\n",
    "    # IMPLEMENT YOUR CODE HERE\n",
    "    # ===================================\n",
    "\n",
    "    # Step 04: Convert MEL-Spectrogram to log scale\n",
    "    # ===================================\n",
    "    # IMPLEMENT YOUR CODE HERE\n",
    "    # ===================================\n",
    "    \n",
    "    \n",
    "    # Step 05: Define Feature Vector Array\n",
    "    dims = n_mels * frames\n",
    "    length = len(log_mel_spectrogram[0,:]) - frames + 1\n",
    "    features = np.zeros((length, dims), float)\n",
    "    \n",
    "    # Pad short clips instead of skipping\n",
    "    if length < 1:\n",
    "        print(f\"Audio file '{file_name}' is too short. Padding applied.\")\n",
    "        log_mel_spectrogram = np.pad(log_mel_spectrogram, ((0, 0), (0, frames - 1)), mode='constant')\n",
    "        length = 1\n",
    "    \n",
    "    for t in range(frames):\n",
    "        features[:, n_mels * t: n_mels * (t + 1)] = log_mel_spectrogram[:, t: t + length].T\n",
    "    \n",
    "    if plot:\n",
    "        plot_signals(tmin, tmax, sr, y, emphasized_y, log_mel_spectrogram)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_test_file = 'dev_data_pump_04/pump/train/normal_id_04_00000000.wav'\n",
    "# wav_test_file = 'dev_data_pump_04/pump/test/anomaly_id_04_00000000.wav'\n",
    "\n",
    "# Visualize your results for potential analysis in your report\n",
    "features = file_to_features(wav_test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRqlvEaHhCdu"
   },
   "source": [
    "## PyTorch Dataset Splitting\n",
    "\n",
    "To define and optimize a neural network, we will use the library [PyTorch](http://pytorch.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxyR8O5XhBEC"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \".\"\n",
    "MACHINE = \"pump_04\" # Choice between  \"valve_00\" or \"pump_04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwG3y3NnhNB7"
   },
   "outputs": [],
   "source": [
    "class MIMII(Dataset):\n",
    "    def __init__(self, root, machine, train=True, transform=None, target_transform=None):\n",
    "        if train:\n",
    "            self.audio_path = os.path.join(root, f\"dev_data_{machine}\", machine.split(\"_\")[0], \"train\")\n",
    "            self.audio_files = os.listdir(self.audio_path)\n",
    "            self.labels = [int(f.split(\"_\")[0] == \"anomaly\") for f in self.audio_files]\n",
    "        else:\n",
    "            self.audio_path = os.path.join(root, f\"dev_data_{machine}\", machine.split(\"_\")[0], \"test\")\n",
    "            self.audio_files = os.listdir(self.audio_path)\n",
    "            self.labels = [int(f.split(\"_\")[0] == \"anomaly\") for f in self.audio_files]\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.audio_path, self.audio_files[idx])\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            f = self.transform(file_path)\n",
    "        else:\n",
    "            # default feature representation\n",
    "            f = file_to_features(file_path).astype(np.float32)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return f, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZTnxItehN89"
   },
   "outputs": [],
   "source": [
    "# Parameters of the feature extraction\n",
    "melsp_params = dict(n_mels=64,\n",
    "                    frames=10,\n",
    "                    n_fft=1024,\n",
    "                    hop_length=512,\n",
    "                    power=2.0,\n",
    "                    plot=False)\n",
    "\n",
    "\n",
    "feature_extraction_pipeline = T.Compose([\n",
    "    T.Lambda(lambda file: file_to_features(file, **melsp_params).astype(np.float32)),\n",
    "    T.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9MJSPhoPhO89",
    "outputId": "da5765b4-92e2-476f-9704-4ba4649d6647"
   },
   "outputs": [],
   "source": [
    "# Pytorch train/test datasets\n",
    "data_train = MIMII(\n",
    "    root=DATA_PATH,\n",
    "    machine=MACHINE,\n",
    "    train=True,\n",
    "    transform=feature_extraction_pipeline\n",
    ")\n",
    "\n",
    "data_test = MIMII(\n",
    "    root=DATA_PATH,\n",
    "    machine=MACHINE,\n",
    "    train=False,\n",
    "    transform=feature_extraction_pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0C0UJWihYFB"
   },
   "source": [
    "## AutoEncoder Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8jSz2BphWSl"
   },
   "outputs": [],
   "source": [
    "class DenseAutoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "        super(DenseAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            )\n",
    "        \n",
    "        # TODO : write a symetrical neural network to the encoder to reconstuct the input\n",
    "        # ===================================\n",
    "        # IMPLEMENT YOUR CODE HERE\n",
    "        # ===================================\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature = self.encoder(x)\n",
    "        reconstruction = self.decoder(feature)\n",
    "        return reconstruction,feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvFfKbfzhkIA",
    "outputId": "9c63a462-ac42-4782-a909-178bd268d426"
   },
   "outputs": [],
   "source": [
    "duration = 10  # s\n",
    "sr = 16000  # Hz\n",
    "input_dim = int(duration * sr / melsp_params[\"hop_length\"] + 1) * melsp_params[\"n_mels\"] * melsp_params[\"frames\"]\n",
    "model = DenseAutoencoder(input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlKwicqPh4WN"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8TUxt5Lhkoh"
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5r_42qUh6F7"
   },
   "outputs": [],
   "source": [
    "# PyTorch data loaders allow to iterate batch-wise over a dataset\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PLm0cEGh6yG"
   },
   "outputs": [],
   "source": [
    "# Stochastic gradient descent optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Mean Squared Error (MSE) loss function to be minimized\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCWTbrx0h829"
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, print_every=10):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    loss_running = 0\n",
    "    for batch, (x, y) in enumerate(tqdm(dataloader)):\n",
    "        # Compute prediction and loss\n",
    "        x = x.flatten(start_dim=1)\n",
    "        optimizer.zero_grad()\n",
    "        x_pred, features = model(x)\n",
    "        \n",
    "        # TODO : write the loss function, compute the gradient, and update the model parameters\n",
    "        # ===================================\n",
    "        # IMPLEMENT YOUR CODE HERE\n",
    "        # ===================================\n",
    "        \n",
    "        # Back Propagation\n",
    "        loss_running += loss.item()\n",
    "    print(f\"loss: {loss_running/len(dataloader):>7f}\")\n",
    "\n",
    "\n",
    "def test_loop(dataset, model, loss_fn):\n",
    "    size = len(dataset)\n",
    "    test_losses = np.zeros(size)\n",
    "    store_feature = []\n",
    "    with torch.no_grad():\n",
    "        for idx, (x, _) in enumerate(dataset):\n",
    "            x = x.flatten()\n",
    "            x_pred,features = model(x)\n",
    "            store_feature.append(features.detach().cpu().numpy())\n",
    "            test_losses[idx] = loss_fn(x_pred, x).item()\n",
    "\n",
    "    return test_losses, np.array(store_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izqhJT_siUAF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer, print_every=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOq7aGUribck"
   },
   "source": [
    "## Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uS8VF6qOicRh"
   },
   "outputs": [],
   "source": [
    "y_true = data_test.labels\n",
    "test_losses, extracted_features_test = test_loop(data_test, model, loss_fn)\n",
    "y_scores = test_losses\n",
    "\n",
    "metrics.roc_auc_score(y_true, y_scores)\n",
    "\n",
    "# TODO : Define a threshold based on test loss for classification\n",
    "# TODO : Report accuracy, TPR, FPR, F1-Score\n",
    "# ===================================\n",
    "# IMPLEMENT YOUR CODE HERE\n",
    "# ==================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GlPy8HiSigc2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "RocCurveDisplay.from_predictions(y_true, y_scores, name=\"Autoencoder\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "plt.title(f\"Receiver operating characteristic (ROC) curve for {MACHINE}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFWXKbjFiiO4"
   },
   "source": [
    "## One-Class SVM and Isolation Forest\n",
    "\n",
    "From the trained AutoEncoder, use the bottleneck features to train a (1) One-Class SVM and (2) Isolation Forest, and report the accuracy, F1-score and auc score of each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yutJPQg5ioih"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpnrmvn7i8hn"
   },
   "outputs": [],
   "source": [
    "# Get normal training features\n",
    "y_pred_train, extracted_features_train = test_loop(data_train, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HX-BDH08i8_H"
   },
   "source": [
    "### One-Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zzmxgn7iik37"
   },
   "outputs": [],
   "source": [
    "# TODO : Define the OneClassSVM here\n",
    "# TODO : Fit OneClassSVM here using training data\n",
    "# TODO : Report essential evaluation metrics\n",
    "# ===================================\n",
    "# IMPLEMENT YOUR CODE HERE\n",
    "# ===================================\n",
    "\n",
    "metrics.roc_auc_score(y_true, -predicted_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ivg1xIdyjABG"
   },
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsO8gdmAi5Kg"
   },
   "outputs": [],
   "source": [
    "# TODO : Define IsolationForest here\n",
    "# TODO : Fit IsolationForest here using training data\n",
    "# TODO : Report essential evaluation metrics\n",
    "# ===================================\n",
    "# IMPLEMENT YOUR CODE HERE\n",
    "# ===================================\n",
    "\n",
    "metrics.roc_auc_score(y_true, -predicted_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_5bTEeMjMoR"
   },
   "source": [
    "PCA of the spectrograms to reduce the input dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0UHfthQjQ_h"
   },
   "outputs": [],
   "source": [
    "# Extract spectrograms of training and testing\n",
    "flatten_spectogram_train = []\n",
    "for idx, (x, _) in enumerate(data_train):\n",
    "    x = x.flatten()\n",
    "    flatten_spectogram_train.append(x.numpy())\n",
    "train_spec = np.array(flatten_spectogram_train)\n",
    "\n",
    "flatten_spectogram_test = []\n",
    "for idx, (x, _) in enumerate(data_test):\n",
    "    x = x.flatten()\n",
    "    flatten_spectogram_test.append(x.numpy())\n",
    "test_spec = np.array(flatten_spectogram_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYVoyGx8jWKA"
   },
   "source": [
    "Apply PCA to fit and transform the training data and transform also the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4U1oqcStjep0"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=64)\n",
    "\n",
    "# TODO : Fit and transform the training data (train_spec)\n",
    "# TODO : Transform the testing data (test_spec)\n",
    "# ===================================\n",
    "# IMPLEMENT YOUR CODE HERE\n",
    "# ==================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcEezkFDjrL6"
   },
   "source": [
    "Apply OneClassSVM and IsolationForest on the new PCA features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Define the OneClassSVM here\n",
    "# TODO : Fit OneClassSVM here using PCA features\n",
    "# TODO : Report essential evaluation metrics\n",
    "# ===================================\n",
    "# IMPLEMENT YOUR CODE HERE\n",
    "# ===================================\n",
    "\n",
    "metrics.roc_auc_score(y_true, -predicted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Define IsolationForest here\n",
    "# TODO : Fit IsolationForest here using PCA features\n",
    "# TODO : Report essential evaluation metrics\n",
    "# ===================================\n",
    "# IMPLEMENT YOUR CODE HERE\n",
    "# ===================================\n",
    "\n",
    "metrics.roc_auc_score(y_true, -predicted_score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "smplx",
   "language": "python",
   "name": "smplx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
